{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import datasets\n",
    "import torch\n",
    "from torch.utils.data import DataLoader \n",
    "from transformers import  AutoModel,AutoTokenizer,AutoConfig,DataCollatorForSeq2Seq\n",
    "from config.config import cfg\n",
    "from finglm.utils import preprocess\n",
    "from finglm.train import StepRunner \n",
    "from torchkeras import KerasModel \n",
    "from accelerate import Accelerator\n",
    "from datetime import datetime,date\n",
    "from finglm.utils import *\n",
    "from logging import Logger\n",
    "\n",
    "year_list = [2021,2022,2023]\n",
    "\n",
    "data_all = load_data_all(year_list)\n",
    "\n",
    "rolling_date_config = generate_rolling_date_config(data=data_all,rolling_window=5,year_list = year_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type chatglm to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05122165040b40f8acfd5fc9255e27ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(cfg.model_name_or_path['chatglm2-6b'], trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(cfg.model_name_or_path['chatglm2-6b'], trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(cfg.model_name_or_path['chatglm2-6b'],config=config,trust_remote_code=True).half().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rolling Times: 30\n",
      " Traning Period: 2021/1 - 2021/6 \n",
      " Test Period: 2021/8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7a89c44060142e886e13b8e1ce83626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/9927 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d481d2ce4fc4236b1227b75e038a42e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/1376 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 2924880 || all params: 6246508908 || trainable%: 0.04682423483386154\n",
      "\u001b[0;31m<<<<<< ⚡️ cuda is used >>>>>>\u001b[0m\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* background: */\n",
       "    progress::-webkit-progress-bar {background-color: #CDCDCD; width: 100%;}\n",
       "    progress {background-color: #CDCDCD;}\n",
       "\n",
       "    /* value: */\n",
       "    progress::-webkit-progress-value {background-color: #00BFFF  !important;}\n",
       "    progress::-moz-progress-bar {background-color: #00BFFF  !important;}\n",
       "    progress {color: #00BFFF ;}\n",
       "\n",
       "    /* optional */\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #000000;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0% [0/5]\n",
       "      <br>\n",
       "      █▋                  8.25% [375/4548] [train_loss=0.50342,lr=0.00500]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for idx in range(rolling_date_config['rolling times']):\n",
    "    start_year,start_month = rolling_date_config['training_start']['period'][idx]\n",
    "    end_year,end_month = rolling_date_config['training_end']['period'][idx]\n",
    "    validation_year,validation_month = rolling_date_config['validation']['period'][idx]\n",
    "    test_year,test_month = rolling_date_config['test']['period'][idx]\n",
    "\n",
    "\n",
    "    start_date = date(start_year,start_month,1).strftime(\"%Y-%m-%d\")\n",
    "    _,lastday = calendar.monthrange(end_year,end_month)\n",
    "    end_date = date(end_year,end_month,lastday).strftime(\"%Y-%m-%d\")\n",
    "    train_df = data_all[(data_all['publishDate']>=start_date) &  (data_all['publishDate']<=end_date)]\n",
    "    validation_df = data_all.query(f'year == {validation_year} and month == {validation_month}')\n",
    "    test_df = data_all.query(f'year == {test_year} and month == {test_month}')\n",
    "    ds_train_raw = datasets.Dataset.from_pandas(train_df[['prompt','response']])\n",
    "    ds_val_raw = datasets.Dataset.from_pandas(validation_df[['prompt','response']])\n",
    "    ds_test_raw = datasets.Dataset.from_pandas(test_df[['prompt','response']])\n",
    "\n",
    "    logging_info = f\"{datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} Starting LoRA finetune task for {test_year}/{test_month}\\n\"\n",
    "    with open('log/train.log','a') as f:\n",
    "        f.write(logging_info)\n",
    "    print(logging_info)\n",
    "    \n",
    "    ds_train = ds_train_raw.map(\n",
    "        preprocess,\n",
    "        batched= True,\n",
    "        num_proc= 4,\n",
    "        remove_columns=ds_train_raw.column_names,\n",
    "        fn_kwargs={'tokenizer':tokenizer,'cfg':cfg}\n",
    "    )\n",
    "    ds_val = ds_val_raw.map(\n",
    "        preprocess,\n",
    "        batched = True,\n",
    "        num_proc=4,\n",
    "        remove_columns= ds_val_raw.column_names,\n",
    "        fn_kwargs={'tokenizer':tokenizer,'cfg':cfg}\n",
    "    )\n",
    "\n",
    "\n",
    "    data_collator = DataCollatorForSeq2Seq( \n",
    "        tokenizer,\n",
    "        model=None,\n",
    "        label_pad_token_id=-100,\n",
    "        pad_to_multiple_of=None,\n",
    "        padding=False\n",
    "    )\n",
    "\n",
    "\n",
    "    dl_train = DataLoader(ds_train,batch_size = cfg.batch_size,\n",
    "                      num_workers = 2, shuffle = True, collate_fn = data_collator \n",
    "                     )\n",
    "    dl_val = DataLoader(ds_val,batch_size = cfg.batch_size,\n",
    "                      num_workers = 2, shuffle = False, collate_fn = data_collator \n",
    "                     )\n",
    "    \n",
    "\n",
    "    from peft import get_peft_model, AdaLoraConfig, TaskType,PeftModel\n",
    "\n",
    "    #训练时节约GPU占用\n",
    "    model.config.use_cache=False\n",
    "    model.supports_gradient_checkpointing = True  #\n",
    "    model.gradient_checkpointing_enable()\n",
    "    model.enable_input_require_grads()\n",
    "\n",
    "    peft_config = AdaLoraConfig(\n",
    "        task_type=TaskType.CAUSAL_LM, inference_mode=False,\n",
    "        r=100,\n",
    "        lora_alpha=32, lora_dropout=0.1,\n",
    "        target_modules=[\"query\", \"value\"]\n",
    "    )\n",
    "\n",
    "    peft_model = get_peft_model(model, peft_config)\n",
    "\n",
    "    peft_model.is_parallelizable = True\n",
    "    peft_model.model_parallel = True\n",
    "    peft_model.print_trainable_parameters()\n",
    "\n",
    "    KerasModel.StepRunner = StepRunner \n",
    "\n",
    "\n",
    " \n",
    "        \n",
    "    KerasModel.save_ckpt = save_ckpt \n",
    "    KerasModel.load_ckpt = load_ckpt \n",
    "    optimizer = torch.optim.AdamW(peft_model.parameters(),lr=cfg.lr) \n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer = optimizer,step_size = cfg.scheduler_steps,gamma = cfg.scheduler_gamma)\n",
    "    keras_model = KerasModel(peft_model,loss_fn =None,\n",
    "            optimizer=optimizer,\n",
    "            lr_scheduler=lr_scheduler\n",
    "            ) \n",
    "    ckpt_path = f'finglm/six_month_rolling/{test_year}_{test_month}'\n",
    "    import os\n",
    "    if not os.path.exists(ckpt_path):\n",
    "        os.mkdir(ckpt_path)\n",
    "\n",
    "\n",
    "    keras_model.fit(train_data = dl_train,\n",
    "                val_data = dl_val,\n",
    "                epochs=cfg.epochs,\n",
    "                patience=20,\n",
    "                monitor='val_loss',\n",
    "                mode='min',\n",
    "                ckpt_path = ckpt_path,\n",
    "                mixed_precision='fp16',\n",
    "                gradient_accumulation_steps = cfg.gradient_accumulation_steps\n",
    "               )\n",
    "    \n",
    "    del peft_model\n",
    "    torch.cuda.empty_cache()\n",
    "    with open('log/train.log','a') as f:\n",
    "        f.write(f\"\\n {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} LoRA task done for {test_year}/{test_month}\\n \"  )\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d516ef738a1c43e3b56b1f62e85df787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15851dc97c954463ab3b1facd1993b29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = data_all[:500]\n",
    "df_val = data_all[500:600]\n",
    "\n",
    "ds_train_raw = datasets.Dataset.from_pandas(df_train)\n",
    "ds_val_raw = datasets.Dataset.from_pandas(df_val)\n",
    "\n",
    "ds_train = ds_train_raw.map(preprocess,batched=True,num_proc=4,remove_columns=ds_train_raw.column_names,fn_kwargs={\"tokenizer\":tokenizer,\"cfg\":cfg})\n",
    "ds_val = ds_train_raw.map(preprocess,batched=True,num_proc=4,remove_columns=ds_val_raw.column_names,fn_kwargs={\"tokenizer\":tokenizer,\"cfg\":cfg})\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "        tokenizer,\n",
    "        model=None,\n",
    "        label_pad_token_id=-100,\n",
    "        pad_to_multiple_of=None,\n",
    "        padding=False\n",
    ")\n",
    "dl_train = DataLoader(ds_train,batch_size = cfg.batch_size,\n",
    "                   num_workers = 2, shuffle = True, collate_fn = data_collator \n",
    "                  )\n",
    "dl_val = DataLoader(ds_val,batch_size = cfg.batch_size,\n",
    "                      num_workers = 2, shuffle = False, collate_fn = data_collator \n",
    "                     )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">12</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> batch <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> dl_train:                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">10 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>input_id , label = batch[<span style=\"color: #808000; text-decoration-color: #808000\">'input_ids'</span>],batch[<span style=\"color: #808000; text-decoration-color: #808000\">'labels'</span>]                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">11 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>logits = model(input_ids =input_id,labels= label).logits                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>12 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>model.generate(logits)                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">13 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>accelerator.backward(loss)                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>optimizer.step()                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>scheduler.step()                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">TypeError: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PeftModelForCausalLM.generate</span><span style=\"font-weight: bold\">()</span> takes <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> positional argument but <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> were given\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m12\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 9 \u001b[0m\u001b[94mfor\u001b[0m batch \u001b[95min\u001b[0m dl_train:                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m10 \u001b[0m\u001b[2m│   \u001b[0minput_id , label = batch[\u001b[33m'\u001b[0m\u001b[33minput_ids\u001b[0m\u001b[33m'\u001b[0m],batch[\u001b[33m'\u001b[0m\u001b[33mlabels\u001b[0m\u001b[33m'\u001b[0m]                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m11 \u001b[0m\u001b[2m│   \u001b[0mlogits = model(input_ids =input_id,labels= label).logits                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m12 \u001b[2m│   \u001b[0mmodel.generate(logits)                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m13 \u001b[0m\u001b[2m│   \u001b[0maccelerator.backward(loss)                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m14 \u001b[0m\u001b[2m│   \u001b[0moptimizer.step()                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m15 \u001b[0m\u001b[2m│   \u001b[0mscheduler.step()                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mTypeError: \u001b[0m\u001b[1;35mPeftModelForCausalLM.generate\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m takes \u001b[1;36m1\u001b[0m positional argument but \u001b[1;36m2\u001b[0m were given\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from accelerate import Accelerator\n",
    "accelerator = Accelerator()\n",
    "device = accelerator.device\n",
    "peft_model.to(device)\n",
    "optimizer = torch.optim.AdamW(peft_model.parameters(),lr = 0.0005)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer=optimizer,step_size=100)\n",
    "\n",
    "model,optimizer,dl_train,scheduler = accelerator.prepare(peft_model,optimizer,dl_train,lr_scheduler)\n",
    "for batch in dl_train:\n",
    "    input_id , label = batch['input_ids'],batch['labels']\n",
    "    logits = model(input_ids =input_id,labels= label).logits\n",
    "    model.generate(logits)\n",
    "    accelerator.backward(loss)\n",
    "    optimizer.step()\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model \n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model_old = AutoModel.from_pretrained(cfg.model_name_or_path['chatglm2-6b'],\n",
    "                              load_in_8bit=False, \n",
    "                              trust_remote_code=True)\n",
    "peft_loaded = PeftModel.from_pretrained(model_old,ckpt_path).cuda()\n",
    "model_new = peft_loaded.merge_and_unload() #合并lora权重\n",
    "answer = {'prompt':[],'response':[]}\n",
    "for prompt in test_df['prompt']:\n",
    "    input_prompt = cfg.source_prefix+prompt\n",
    "    answer['prompt'].append(prompt)\n",
    "    answer['response'].append(model.chat(query=input_prompt , tokenizer = tokenizer)[0])\n",
    "answer = pd.DataFrame(answer)\n",
    "test_df = pd.concat([answer,test_df],axis = 1)\n",
    "answer.to_csv(f'data/finglm_answers/{test_year}_{test_month}.csv',index=  False) \n",
    "model_new.save_pretrained('/root/autodl-tmp/models/finGLM')\n",
    "tokenizer.save_pretrained('/root/autodl-tmp/models/finGLM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer,\n",
    "    model=None,\n",
    "    label_pad_token_id=-100,\n",
    "    pad_to_multiple_of=None,\n",
    "    padding=False\n",
    ")\n",
    "\n",
    "dl_train = DataLoader(ds_train,batch_size = cfg.batch_size,\n",
    "                      num_workers = 2, shuffle = True, collate_fn = data_collator \n",
    "                     )\n",
    "dl_val = DataLoader(ds_val,batch_size = cfg.batch_size,\n",
    "                      num_workers = 2, shuffle = False, collate_fn = data_collator \n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import get_peft_model, AdaLoraConfig, TaskType\n",
    "\n",
    "#训练时节约GPU占用\n",
    "model.config.use_cache=False\n",
    "model.supports_gradient_checkpointing = True  #\n",
    "model.gradient_checkpointing_enable()\n",
    "model.enable_input_require_grads()\n",
    "\n",
    "peft_config = AdaLoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM, inference_mode=False,\n",
    "    r=8,\n",
    "    lora_alpha=32, lora_dropout=0.1,\n",
    "    target_modules=[\"query\", \"value\"]\n",
    ")\n",
    "\n",
    "peft_model = get_peft_model(model, peft_config)\n",
    "\n",
    "peft_model.is_parallelizable = True\n",
    "peft_model.model_parallel = True\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchkeras import KerasModel \n",
    "from accelerate import Accelerator \n",
    "\n",
    "class StepRunner:\n",
    "    def __init__(self, net, loss_fn, accelerator=None, stage = \"train\", metrics_dict = None, \n",
    "                 optimizer = None, lr_scheduler = None\n",
    "                 ):\n",
    "        self.net,self.loss_fn,self.metrics_dict,self.stage = net,loss_fn,metrics_dict,stage\n",
    "        self.optimizer,self.lr_scheduler = optimizer,lr_scheduler\n",
    "        self.accelerator = accelerator if accelerator is not None else Accelerator() \n",
    "        if self.stage=='train':\n",
    "            self.net.train() \n",
    "        else:\n",
    "            self.net.eval()\n",
    "    \n",
    "    def __call__(self, batch):\n",
    "        \n",
    "        #loss\n",
    "        with self.accelerator.autocast():\n",
    "            loss = self.net(input_ids=batch[\"input_ids\"],labels=batch[\"labels\"]).loss\n",
    "\n",
    "        #backward()\n",
    "        if self.optimizer is not None and self.stage==\"train\":\n",
    "            self.accelerator.backward(loss)\n",
    "            if self.accelerator.sync_gradients:\n",
    "                self.accelerator.clip_grad_norm_(self.net.parameters(), 1.0)\n",
    "            self.optimizer.step()\n",
    "            if self.lr_scheduler is not None:\n",
    "                self.lr_scheduler.step()\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "        all_loss = self.accelerator.gather(loss).sum()\n",
    "        \n",
    "        #losses (or plain metrics that can be averaged)\n",
    "        step_losses = {self.stage+\"_loss\":all_loss.item()}\n",
    "        \n",
    "        #metrics (stateful metrics)\n",
    "        step_metrics = {}\n",
    "        \n",
    "        if self.stage==\"train\":\n",
    "            if self.optimizer is not None:\n",
    "                step_metrics['lr'] = self.optimizer.state_dict()['param_groups'][0]['lr']\n",
    "            else:\n",
    "                step_metrics['lr'] = 0.0\n",
    "        return step_losses,step_metrics\n",
    "    \n",
    "KerasModel.StepRunner = StepRunner \n",
    "\n",
    "\n",
    "#仅仅保存lora相关的可训练参数\n",
    "def save_ckpt(self, ckpt_path='checkpoint', accelerator = None):\n",
    "    unwrap_net = accelerator.unwrap_model(self.net)\n",
    "    unwrap_net.save_pretrained(ckpt_path)\n",
    "    \n",
    "def load_ckpt(self, ckpt_path='checkpoint'):\n",
    "    self.net = self.net.from_pretrained(self.net.base_model.model,ckpt_path)\n",
    "    self.from_scratch = False\n",
    "    \n",
    "KerasModel.save_ckpt = save_ckpt \n",
    "KerasModel.load_ckpt = load_ckpt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(peft_model.parameters(),lr=cfg.lr) \n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer = optimizer,step_size = 1000,gamma = 0.5)\n",
    "keras_model = KerasModel(peft_model,loss_fn =None,\n",
    "        optimizer=optimizer,\n",
    "        lr_scheduler=lr_scheduler\n",
    "        ) \n",
    "ckpt_path = 'finglm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "keras_model.fit(train_data = dl_train,\n",
    "                val_data = dl_val,\n",
    "                epochs=cfg.epochs,\n",
    "                patience=20,\n",
    "                monitor='val_loss',\n",
    "                mode='min',\n",
    "                ckpt_path = ckpt_path,\n",
    "                mixed_precision='fp16',\n",
    "                gradient_accumulation_steps = cfg.gradient_accumulation_steps\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel \n",
    "from transformers import AutoModel\n",
    "ckpt_path = 'finglm'\n",
    "model_old = AutoModel.from_pretrained(cfg.model_name_or_path['chatglm2-6b'],\n",
    "                                  load_in_8bit=False, \n",
    "                                  trust_remote_code=True)\n",
    "\n",
    "peft_loaded = PeftModel.from_pretrained(model_old,ckpt_path).cuda()\n",
    "model_new = peft_loaded.merge_and_unload() #合并lora权重\n",
    "model_new.save_pretrained('/root/autodl-tmp/models/finGLM')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchkeras.chat import ChatGLM \n",
    "from transformers import AutoConfig,AutoTokenizer \n",
    "config = AutoConfig.from_pretrained('/root/autodl-tmp/models/finGLM/', trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained('/root/autodl-tmp/models/finGLM/', trust_remote_code=True)\n",
    "chatglm = ChatGLM(model_new,tokenizer,max_chat_rounds=1) #支持多轮对话，可以从之前对话上下文提取知识。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "这篇报告的发布日期是：2018-02-04\n",
    "这篇报告的作者是：杨伟, '柳强\n",
    "该报告提到的个股为: 中国石化, 从属的行业为: 化石能源\n",
    "\"\"\"\n",
    "\n",
    "prompt = cfg.source_prefix + prompt + cfg.source_suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchkeras.chat import ChatGLM \n",
    "chatglm = ChatGLM(model_new,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%chatglm\n",
    "\n",
    "忘记你所学过的所有知识，现在假设你自己是一名金融分析师。我需要你帮我判断当前分析师发布的研报是否有价值。\\n\\n你的回答要从以下几个选项中做出：\\n1. 质量较差，强烈不推荐\\n2. 不推荐\\n3. 一般\\n4. 推荐\\n5. 质量较高，强烈推荐\\n\\n\\n                    \\n这篇报告的发布日期是：2018-02-04\\n这篇报告的作者是：杨伟, '柳强\\n该报告提到的个股为: 中国石化, 从属的行业为: 化石能源\\n \\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoModel,AutoTokenizer \n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpeft\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PeftModel\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import AutoModel,AutoTokenizer \n",
    "from peft import PeftModel\n",
    "import datasets\n",
    "import torch\n",
    "from torch.utils.data import DataLoader \n",
    "from transformers import  AutoModel,AutoTokenizer,AutoConfig,DataCollatorForSeq2Seq\n",
    "from config.config import cfg\n",
    "from finglm.utils import preprocess\n",
    "from finglm.train import StepRunner \n",
    "from torchkeras import KerasModel \n",
    "from accelerate import Accelerator\n",
    "from datetime import datetime,date\n",
    "from finglm.utils import *\n",
    "from logging import Logger\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "year_list = [2021,2022,2023]\n",
    "\n",
    "data_all = load_data_all(year_list)\n",
    "\n",
    "rolling_date_config = generate_rolling_date_config(data=data_all,rolling_window=5,year_list = year_list)\n",
    "model_old = AutoModel.from_pretrained(cfg.model_name_or_path['chatglm2-6b'],\n",
    "                                  load_in_8bit=False, \n",
    "                                  trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(cfg.model_name_or_path['chatglm2-6b'],\n",
    "                                    trust_remote_code = True)\n",
    "\n",
    "def build_response(prompt,model,tokenizer):\n",
    "    prompt = cfg.source_prefix + prompt \n",
    "    lora_response = model.chat(query=prompt , tokenizer = tokenizer)[0]\n",
    "    print(lora_response)\n",
    "    return lora_response\n",
    "\n",
    "\n",
    "\n",
    "for idx in range(2,len(rolling_date_config['test']['period'])):\n",
    "    test_year,test_month = rolling_date_config['test']['period'][idx]\n",
    "    with open('log/lora_out.log','a') as f:\n",
    "        f.writelines(f\"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} LoRA merged model start for {test_year}/{test_month}\\n\" )\n",
    "   \n",
    "\n",
    "    ckpt_path = f'finglm/six_month_rolling/{test_year}_{test_month}'\n",
    "    \n",
    "    output_path = f'data/lora_output_data/six_month_rolling/highly_recommend/{test_year}_{test_month}'\n",
    "    if not os.path.exists(output_path):\n",
    "        os.mkdir(output_path)\n",
    "    test_df = data_all.query(f'year == {test_year} and month == {test_month}')\n",
    "\n",
    "    peft_loaded = PeftModel.from_pretrained(model_old,ckpt_path).cuda()\n",
    "    model_new = peft_loaded.merge_and_unload() #合并lora权重\n",
    "    \n",
    "    test_df['lora_response']= test_df['prompt'].apply(build_response,args = (model_new,tokenizer))\n",
    "    \n",
    "    test_df.to_csv(os.path.join(output_path,'full_result.csv'),index = False) \n",
    "    highly_recommend = test_df[test_df['lora_response']=='该研报质量较高，强烈推荐']\n",
    "    highly_recommend['type'] = 'LoRA'\n",
    "    highly_recommend['sell_week'] = (highly_recommend['week']+4)%12\n",
    "\n",
    "    np.random.seed(1)\n",
    "    random_idx = np.random.choice(len(test_df),10)\n",
    "    recommend_random_idx = np.random.choice(len(test_df),10)\n",
    "    highly_recommend = highly_recommend.iloc[recommend_random_idx]\n",
    "    benchmark = test_df.iloc[random_idx]\n",
    "    benchmark['type'] = 'random'\n",
    "    benchmark['sell_week'] = (benchmark['week']+4)%12\n",
    "    \n",
    "    result_df = pd.concat([highly_recommend,benchmark])\n",
    "    selected_cols = [\"publishDate\",\"stockName\",\"stockCode\",\"week\",\"month\",\"year\",\"sell_week\",\"type\"]\n",
    "    result_df = result_df[selected_cols]\n",
    "\n",
    "    result_df.to_csv(os.path.join(output_path,'choose_result.csv'),index = False)\n",
    "    del peft_loaded\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = AutoModel.from_pretrained('/root/autodl-tmp/models/finGLM',trust_remote_code = True).half()\n",
    "tokenizer = AutoTokenizer.from_pretrained('/root/autodl-tmp/models/finGLM',trust_remote_code = True)\n",
    "\n",
    "model = model.cuda()\n",
    "\n",
    "test_df = pd.read_csv('datasets/2018/prompt_response_short.csv')\n",
    "test_df = test_df[test_df['month'] == 2]\n",
    "answer = {'prompt':[],'response':[]}\n",
    "for prompt in test_df['prompt']:\n",
    "    input_prompt = cfg.source_prefix+prompt\n",
    "    answer['prompt'].append(prompt)\n",
    "    answer['response'].append(model.chat(query=input_prompt , tokenizer = tokenizer)[0])\n",
    "answer = pd.DataFrame(answer)\n",
    "answer.to_csv('datasets/finglm_answers/answer.csv',index=  False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m selected_report \u001b[39m=\u001b[39m \u001b[39m20\u001b[39m\n\u001b[0;32m----> 2\u001b[0m highly_recommend \u001b[39m=\u001b[39m test_df[test_df[\u001b[39m'\u001b[39m\u001b[39mlora_response\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m'\u001b[39m\u001b[39m该研报质量较高，强烈推荐\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mdrop_duplicates(subset\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mstockCode\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m selected_idx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mchoice(\u001b[39mlen\u001b[39m(highly_recommend),\u001b[39m20\u001b[39m)\n\u001b[1;32m      4\u001b[0m selected \u001b[39m=\u001b[39m highly_recommend\u001b[39m.\u001b[39miloc[selected_idx]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "selected_report = 20\n",
    "highly_recommend = test_df[test_df['lora_response']=='该研报质量较高，强烈推荐'].drop_duplicates(subset='stockCode')\n",
    "selected_idx = np.random.choice(len(highly_recommend),20)\n",
    "selected = highly_recommend.iloc[selected_idx]\n",
    "random = test_df.iloc[np.random.choice(len(test_df),20)]\n",
    "\n",
    "\n",
    "selected.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer[answer['response'] == '该研报质量较高，强烈推荐' ].index\n",
    "len(answer[answer['response'] == '推荐持有该个股']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.preprocessor import FinReportPreprocessor\n",
    "processor = FinReportPreprocessor(2017)\n",
    "processor.parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tmp_price = pd.read_csv('data/stock_data/603056.csv',dtype={'代码':'str'})\n",
    "tmp_price.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_price.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_report.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.utils import *\n",
    "import pandas as pd \n",
    "df = pd.read_csv('data/report_processed_data/2017.csv')\n",
    "build_prompt(df)\n",
    "build_response(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prompt'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
