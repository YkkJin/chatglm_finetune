{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification,AutoConfig,DataCollatorForTokenClassification\n",
    "from transformers import AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained('/root/autodl-tmp/models/chatglm3-6b',trust_remote_code = True)\n",
    "tokenizer = AutoTokenizer.from_pretrained('/root/autodl-tmp/models/chatglm3-6b',trust_remote_code = True)\n",
    "config.num_labels = 5\n",
    "config.problem_type = \"multi_label_classification\"\n",
    "config.classifier_dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6d82ac39be64fa99629e511f0148acb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ChatGLMForSequenceClassification were not initialized from the model checkpoint at /root/autodl-tmp/models/chatglm3-6b and are newly initialized: ['classifier_head.weight', 'classifier_head.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('/root/autodl-tmp/models/chatglm3-6b',config = config,trust_remote_code = True).cuda()\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_word = \"\"\"1 这篇报告的发布日期是：2019-12-31\n",
    "这篇报告的作者是：平海庆,杨晶晶,所属机构为 山西证券, 作者给出的评级为: 增持\n",
    "该报告标题为: 第一期员工持股方案落地，深度绑定核心管理层, 该报告提到的个股为: 尚品宅配, 从属的行业为: 木业家具\"\"\"\n",
    "labels = torch.tensor([[0.0,1.0,0.0,0.0,0.0]])\n",
    "input_ids  = tokenizer.build_single_message('user',\"\",input_word)\n",
    "chat_input = tokenizer.build_chat_input(input_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output = model(input_ids = chat_input[\"input_ids\"].to(\"cuda:0\"),labels = labels.to(\"cuda:0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0283,  1.6621, -0.0168,  0.3335, -0.7686]], device='cuda:0',\n",
       "       dtype=torch.float16, grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0212, -0.0049, -0.0067,  ...,  0.0067, -0.0134, -0.0020]],\n",
       "\n",
       "        [[-0.0190,  0.0177, -0.0070,  ...,  0.0048,  0.0238,  0.0181]],\n",
       "\n",
       "        [[-0.0017,  0.0074, -0.0022,  ...,  0.0040, -0.0010,  0.0041]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.0164, -0.0327, -0.0120,  ...,  0.0410,  0.0320,  0.0073]],\n",
       "\n",
       "        [[ 0.0273,  0.0277,  0.0079,  ...,  0.0036, -0.0147, -0.0103]],\n",
       "\n",
       "        [[-0.0029, -0.0020, -0.0090,  ...,  0.0019, -0.0007,  0.0046]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_output = model.transformer.embedding(chat_input[\"input_ids\"].to(\"cuda\"))\n",
    "embedding_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids = tokenizer.encode(input_word)\n",
    "single_message = tokenizer.build_inputs_with_special_tokens(token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gMASK]\n",
      "sop\n",
      "[gMASK]\n",
      "sop\n",
      "▁\n",
      "1\n",
      "<0x09>\n",
      "这篇\n",
      "报告\n",
      "的\n",
      "发布\n",
      "日期\n",
      "是\n",
      "：\n",
      "2\n",
      "0\n",
      "1\n",
      "9\n",
      "-\n",
      "1\n",
      "2\n",
      "-\n",
      "3\n",
      "1\n",
      "<0x0A>\n",
      "这篇\n",
      "报告\n",
      "的作者\n",
      "是\n",
      "：\n",
      "平\n",
      "海\n",
      "庆\n",
      ",\n",
      "杨\n",
      "晶晶\n",
      ",\n",
      "所属\n",
      "机构\n",
      "为\n",
      "▁\n",
      "山西\n",
      "证券\n",
      ",\n",
      "▁作者\n",
      "给出的\n",
      "评级\n",
      "为\n",
      ":\n",
      "▁\n",
      "增\n",
      "持\n",
      "<0x0A>\n",
      "该\n",
      "报告\n",
      "标题\n",
      "为\n",
      ":\n",
      "▁第一\n",
      "期\n",
      "员工\n",
      "持股\n",
      "方案\n",
      "落地\n",
      "，\n",
      "深度\n",
      "绑定\n",
      "核心\n",
      "管理层\n",
      ",\n",
      "▁\n",
      "该\n",
      "报告\n",
      "提到的\n",
      "个股\n",
      "为\n",
      ":\n",
      "▁\n",
      "尚\n",
      "品\n",
      "宅\n",
      "配\n",
      ",\n",
      "▁从\n",
      "属\n",
      "的行业\n",
      "为\n",
      ":\n",
      "▁\n",
      "木\n",
      "业\n",
      "家具\n"
     ]
    }
   ],
   "source": [
    "for input_id in single_message:\n",
    "    print(tokenizer._convert_id_to_token(int(input_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64790"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = torch.randn(4,5)\n",
    "target = torch.empty(4,dtype = torch.int).random_(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.argmax(preds,dim=1) == target)/len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3589, -0.8747,  0.7594,  0.5388,  1.7297],\n",
       "        [ 0.1247, -1.0023, -0.7915,  0.8593,  0.9997],\n",
       "        [-0.2531, -1.3938,  0.4425,  0.1851,  0.8376],\n",
       "        [ 0.5670, -1.0852,  1.7861,  0.8274, -0.4592]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 4, 4, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(preds,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glm3",
   "language": "python",
   "name": "glm3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
